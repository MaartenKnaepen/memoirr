{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Memoirr: Preprocessor + Chunker Pipeline Smoke Test\n",
        "\n",
        "This notebook runs a minimal Haystack pipeline using the SRT preprocessor and the semantic chunker.\n",
        "\n",
        "Requirements:\n",
        "- Ensure a local sentence-transformers model is available under `models/<EMBEDDING_MODEL_NAME>/` (with `model.safetensors` and tokenizer/config files).\n",
        "- `.env` should set `EMBEDDING_MODEL_NAME` (default included in repo). Optionally set `EMBEDDING_DEVICE` (e.g., `cuda:0`).\n",
        "\n",
        "Notes:\n",
        "- The preprocessor emits cleaned JSONL lines, one per caption.\n",
        "- The chunker uses Chonkie SemanticChunker with the self-hosted embeddings to create time-aware chunks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e9fbc022",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EMBEDDING_MODEL_NAME = qwen3-embedding-0.6B\n",
            "EMBEDDING_DEVICE     = \n",
            "Found candidate model dir at: models/chunker/qwen3-embedding-0.6B\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pathlib\n",
        "import textwrap\n",
        "from src.core.config import get_settings\n",
        "\n",
        "settings = get_settings()\n",
        "print('EMBEDDING_MODEL_NAME =', settings.embedding_model_name)\n",
        "print('EMBEDDING_DEVICE     =', settings.device)\n",
        "\n",
        "# Quick existence check to help the user\n",
        "model_path = pathlib.Path('models') / settings.embedding_model_name\n",
        "if not model_path.exists():\n",
        "    # Fallback: search by terminal folder name (case-insensitive), similar to runtime resolver\n",
        "    target = settings.embedding_model_name.split('/')[-1].lower()\n",
        "    candidates = [p for p in pathlib.Path('models').rglob('*') if p.is_dir() and p.name.lower() == target]\n",
        "    if candidates:\n",
        "        print('Found candidate model dir at:', candidates[0])\n",
        "    else:\n",
        "        print('WARNING: Expected model folder not found under models/. The chunker cell may fail.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1295a593",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1\n",
            "00:00:01,000 --> 00:00:02,000\n",
            "- Hello there!\n",
            "\n",
            "2\n",
            "00:00:02,100 --> 00:00:03,000\n",
            "How are you doing?\n",
            "\n",
            "3\n",
            "00:00:03,100 --> 00:00:04,000\n",
            "I'm fine. Thanks!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sample SRT content (very small)\n",
        "sample_srt = textwrap.dedent('''\n",
        "1\n",
        "00:00:01,000 --> 00:00:02,000\n",
        "- Hello there!\n",
        "\n",
        "2\n",
        "00:00:02,100 --> 00:00:03,000\n",
        "How are you doing?\n",
        "\n",
        "3\n",
        "00:00:03,100 --> 00:00:04,000\n",
        "I'm fine. Thanks!\n",
        "''')\n",
        "print(sample_srt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "end_to_end_pipeline",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:11.007811Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPipelines module initialized  \u001b[0m \u001b[36mavailable_pipelines\u001b[0m=\u001b[35m['srt_to_qdrant']\u001b[0m \u001b[36menvironment\u001b[0m=\u001b[35mdevelopment\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mpipelines\u001b[0m \u001b[36mservice\u001b[0m=\u001b[35mmemoirr\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:11.227922Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mBuilding SRT-to-Qdrant pipeline\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_builder\u001b[0m \u001b[36mpipeline_type\u001b[0m=\u001b[35msrt_to_qdrant\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building the complete SRT-to-Qdrant pipeline...\n",
            "{'pipeline_type': 'srt_to_qdrant', 'component': 'pipeline_builder', 'event': 'Building SRT-to-Qdrant pipeline', 'level': 'info', 'timestamp': '2025-09-20T18:59:11.227922Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:14.556358Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSRTPreprocessor initialized   \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mdedupe_window_ms\u001b[0m=\u001b[35m1000\u001b[0m \u001b[36mmin_len\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'min_len': 1, 'dedupe_window_ms': 1000, 'component': 'preprocessor', 'event': 'SRTPreprocessor initialized', 'level': 'info', 'timestamp': '2025-09-20T18:59:14.556358Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:14.558475Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSemanticChunker initialized   \u001b[0m \u001b[36mchunk_size\u001b[0m=\u001b[35m512\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36mmin_sentences\u001b[0m=\u001b[35m2\u001b[0m \u001b[36msimilarity_window\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mthreshold\u001b[0m=\u001b[35m0.75\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'threshold': '0.75', 'chunk_size': 512, 'similarity_window': 3, 'min_sentences': 2, 'component': 'chunker', 'event': 'SemanticChunker initialized', 'level': 'info', 'timestamp': '2025-09-20T18:59:14.558475Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:14.559617Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mChunkJsonlToTexts initialized \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'component': 'pipeline_glue', 'event': 'ChunkJsonlToTexts initialized', 'level': 'info', 'timestamp': '2025-09-20T18:59:14.559617Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:14.561225Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel resolved via recursive search\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mmodel_utils\u001b[0m \u001b[36mmethod\u001b[0m=\u001b[35mrecursive\u001b[0m \u001b[36mmodel_name\u001b[0m=\u001b[35mqwen3-embedding-0.6B\u001b[0m \u001b[36mresolved_path\u001b[0m=\u001b[35mmodels/chunker/qwen3-embedding-0.6B\u001b[0m \u001b[36mtotal_candidates\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'qwen3-embedding-0.6B', 'resolved_path': 'models/chunker/qwen3-embedding-0.6B', 'method': 'recursive', 'total_candidates': 1, 'component': 'model_utils', 'event': 'Model resolved via recursive search', 'level': 'info', 'timestamp': '2025-09-20T18:59:14.561225Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:14.562325Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEmbedding model resolved successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36mmodel_name\u001b[0m=\u001b[35mqwen3-embedding-0.6B\u001b[0m \u001b[36mmodel_path\u001b[0m=\u001b[35mmodels/chunker/qwen3-embedding-0.6B\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'qwen3-embedding-0.6B', 'model_path': 'models/chunker/qwen3-embedding-0.6B', 'component': 'embedder', 'event': 'Embedding model resolved successfully', 'level': 'info', 'timestamp': '2025-09-20T18:59:14.562325Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:14.739626Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLoad pretrained SentenceTransformer: models/chunker/qwen3-embedding-0.6B\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m227\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load pretrained SentenceTransformer: models/chunker/qwen3-embedding-0.6B\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.060964Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m1 prompt is loaded, with the key: query\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m378\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 prompt is loaded, with the key: query\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.062182Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTextEmbedder initialized successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36membedding_dimension\u001b[0m=\u001b[35m1024\u001b[0m \u001b[36mmodel_name\u001b[0m=\u001b[35mqwen3-embedding-0.6B\u001b[0m \u001b[36mmodel_path\u001b[0m=\u001b[35mmodels/chunker/qwen3-embedding-0.6B\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'qwen3-embedding-0.6B', 'embedding_dimension': 1024, 'model_path': 'models/chunker/qwen3-embedding-0.6B', 'component': 'embedder', 'event': 'TextEmbedder initialized successfully', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.062182Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.062996Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mBuildDocuments initialized    \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'component': 'pipeline_glue', 'event': 'BuildDocuments initialized', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.062996Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.063903Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mQdrantWriter initialized successfully\u001b[0m \u001b[36mcollection_name\u001b[0m=\u001b[35mmemoirr\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_writer\u001b[0m \u001b[36membedding_dimension\u001b[0m=\u001b[35m1024\u001b[0m \u001b[36mqdrant_url\u001b[0m=\u001b[35mhttp://localhost:6300\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'qdrant_url': 'http://localhost:6300', 'collection_name': 'memoirr', 'embedding_dimension': 1024, 'component': 'qdrant_writer', 'event': 'QdrantWriter initialized successfully', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.063903Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.064747Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSRT-to-Qdrant pipeline built successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_builder\u001b[0m \u001b[36mcomponent_names\u001b[0m=\u001b[35m['pre', 'chunk', 'explode', 'embed', 'docs', 'write']\u001b[0m \u001b[36mpipeline_type\u001b[0m=\u001b[35msrt_to_qdrant\u001b[0m \u001b[36mtotal_components\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mtotal_connections\u001b[0m=\u001b[35m7\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'total_components': 6, 'component_names': ['pre', 'chunk', 'explode', 'embed', 'docs', 'write'], 'total_connections': 7, 'pipeline_type': 'srt_to_qdrant', 'component': 'pipeline_builder', 'event': 'SRT-to-Qdrant pipeline built successfully', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.064747Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.080756Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component pre         \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mpre\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline components:\n",
            "  - pre\n",
            "  - chunk\n",
            "  - explode\n",
            "  - embed\n",
            "  - docs\n",
            "  - write\n",
            "Pipeline connections:\n",
            "  - pre → chunk\n",
            "  - chunk → explode\n",
            "  - explode → embed\n",
            "  - explode → docs\n",
            "  - explode → docs\n",
            "  - embed → docs\n",
            "  - docs → write\n",
            "Running pipeline on sample SRT...\n",
            "Running component pre\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.081890Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1msrt_preprocessing_started     \u001b[0m \u001b[36minput_length\u001b[0m=\u001b[35m151\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35msrt_preprocessing\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'srt_preprocessing', 'input_length': 151, 'event': 'srt_preprocessing_started', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.081890Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.082574Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting SRT preprocessing    \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mdedupe_window_ms\u001b[0m=\u001b[35m1000\u001b[0m \u001b[36minput_size_chars\u001b[0m=\u001b[35m151\u001b[0m \u001b[36mmin_len\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_size_chars': 151, 'min_len': 1, 'dedupe_window_ms': 1000, 'component': 'preprocessor', 'event': 'Starting SRT preprocessing', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.082574Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.260298Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCaption language filtering completed\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mdropped_captions\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mdropped_lines\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mkept_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mkept_lines\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mtotal_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mtotal_lines\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'total_captions': 3, 'kept_captions': 3, 'dropped_captions': 0, 'total_lines': 3, 'kept_lines': 3, 'dropped_lines': 0, 'component': 'language_filter', 'event': 'Caption language filtering completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.260298Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.261546Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_language_filtered_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_language_filtered_total', 'metric_type': 'counter', 'value': 3, 'component': 'language_filter', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.261546Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.262247Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_kept_after_language_filter\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mkept\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_kept_after_language_filter', 'metric_type': 'counter', 'value': 3, 'component': 'language_filter', 'status': 'kept', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.262247Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.262833Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_dropped_after_language_filter\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mdropped\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_dropped_after_language_filter', 'metric_type': 'counter', 'value': 0, 'component': 'language_filter', 'status': 'dropped', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.262833Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.263282Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mlines_language_filtered_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'lines_language_filtered_total', 'metric_type': 'counter', 'value': 3, 'component': 'language_filter', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.263282Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.263660Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mlines_kept_after_language_filter\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mkept\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'lines_kept_after_language_filter', 'metric_type': 'counter', 'value': 3, 'component': 'language_filter', 'status': 'kept', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.263660Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.264110Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mlines_dropped_after_language_filter\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mdropped\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'lines_dropped_after_language_filter', 'metric_type': 'counter', 'value': 0, 'component': 'language_filter', 'status': 'dropped', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.264110Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.264641Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_processed_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_processed_total', 'metric_type': 'counter', 'value': 0, 'component': 'preprocessor', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.264641Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.265096Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_kept_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mkept\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_kept_total', 'metric_type': 'counter', 'value': 3, 'component': 'preprocessor', 'status': 'kept', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.265096Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.265509Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_dropped_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mreason\u001b[0m=\u001b[35mempty\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_dropped_total', 'metric_type': 'counter', 'value': 0, 'component': 'preprocessor', 'reason': 'empty', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.265509Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.265911Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_dropped_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mreason\u001b[0m=\u001b[35mnon_english\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_dropped_total', 'metric_type': 'counter', 'value': 0, 'component': 'preprocessor', 'reason': 'non_english', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.265911Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.266342Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_deduped_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mreason\u001b[0m=\u001b[35mduplicate\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_deduped_total', 'metric_type': 'counter', 'value': 0, 'component': 'preprocessor', 'reason': 'duplicate', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.266342Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.266765Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSRT preprocessing completed   \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36moutput_lines\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mprocessing_stats\u001b[0m=\u001b[35m{'total_captions': 3, 'kept': 3, 'dropped_empty': 0, 'dropped_non_english': 0, 'deduped': 0}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'output_lines': 3, 'processing_stats': {'total_captions': 3, 'kept': 3, 'dropped_empty': 0, 'dropped_non_english': 0, 'deduped': 0}, 'component': 'preprocessor', 'event': 'SRT preprocessing completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.266765Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.267166Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1msrt_preprocessing_completed   \u001b[0m \u001b[36mcaptions_dropped\u001b[0m=\u001b[35m-3\u001b[0m \u001b[36mcaptions_kept\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m185\u001b[0m \u001b[36minput_length\u001b[0m=\u001b[35m151\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35msrt_preprocessing\u001b[0m \u001b[36moutput_lines\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'srt_preprocessing', 'duration_ms': 185, 'input_length': 151, 'output_lines': 3, 'captions_kept': 3, 'captions_dropped': -3, 'event': 'srt_preprocessing_completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.267166Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.267858Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component chunk       \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mchunk\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component chunk\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.268644Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1msemantic_chunking_started     \u001b[0m \u001b[36minput_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35msemantic_chunking\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'semantic_chunking', 'input_captions': 3, 'event': 'semantic_chunking_started', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.268644Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.269056Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting semantic chunking    \u001b[0m \u001b[36mchunk_size\u001b[0m=\u001b[35m512\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36minput_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mthreshold\u001b[0m=\u001b[35m0.75\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_captions': 3, 'threshold': '0.75', 'chunk_size': 512, 'component': 'chunker', 'event': 'Starting semantic chunking', 'level': 'info', 'timestamp': '2025-09-20T18:59:16.269056Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.272247Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mUse pytorch device_name: cuda:0\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m219\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use pytorch device_name: cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:16.272697Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLoad pretrained SentenceTransformer: models/chunker/qwen3-embedding-0.6B\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m227\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load pretrained SentenceTransformer: models/chunker/qwen3-embedding-0.6B\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.320625Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m1 prompt is loaded, with the key: query\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m378\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 prompt is loaded, with the key: query\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.323437Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_chunked_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_chunked_total', 'metric_type': 'counter', 'value': 3, 'component': 'chunker', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.323437Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.324682Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mchunks_generated_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'chunks_generated_total', 'metric_type': 'counter', 'value': 1, 'component': 'chunker', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.324682Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.325880Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_histogram              \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mavg_tokens_per_chunk\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mhistogram\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m15.0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'avg_tokens_per_chunk', 'metric_type': 'histogram', 'value': 15.0, 'component': 'chunker', 'event': 'metric_histogram', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.325880Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.326890Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSemantic chunking completed   \u001b[0m \u001b[36mavg_tokens_per_chunk\u001b[0m=\u001b[35m15.0\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36minput_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36moutput_chunks\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_captions': 3, 'output_chunks': 1, 'avg_tokens_per_chunk': 15.0, 'component': 'chunker', 'event': 'Semantic chunking completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.326890Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.327917Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1msemantic_chunking_completed   \u001b[0m \u001b[36mavg_tokens_per_chunk\u001b[0m=\u001b[35m15.0\u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m1059\u001b[0m \u001b[36minput_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35msemantic_chunking\u001b[0m \u001b[36moutput_chunks\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moutput_chunks_final\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'semantic_chunking', 'duration_ms': 1059, 'input_captions': 3, 'output_chunks': 1, 'avg_tokens_per_chunk': 15.0, 'output_chunks_final': 1, 'event': 'semantic_chunking_completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.327917Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.328911Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component explode     \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mexplode\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component explode\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.329484Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mchunk_jsonl_parsing_started   \u001b[0m \u001b[36minput_lines\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mchunk_jsonl_parsing\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'chunk_jsonl_parsing', 'input_lines': 1, 'event': 'chunk_jsonl_parsing_started', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.329484Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.330110Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mchunk_lines_processed_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'chunk_lines_processed_total', 'metric_type': 'counter', 'value': 1, 'component': 'pipeline_glue', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.330110Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.330677Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mtexts_extracted_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'texts_extracted_total', 'metric_type': 'counter', 'value': 1, 'component': 'pipeline_glue', 'status': 'success', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.330677Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.331224Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mChunk JSONL parsing completed \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36minput_lines\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moutput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mskipped_lines\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_lines': 1, 'output_texts': 1, 'skipped_lines': 0, 'component': 'pipeline_glue', 'event': 'Chunk JSONL parsing completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.331224Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.331752Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mchunk_jsonl_parsing_completed \u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m2\u001b[0m \u001b[36minput_lines\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mchunk_jsonl_parsing\u001b[0m \u001b[36moutput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mskipped_lines\u001b[0m=\u001b[35m0\u001b[0m \u001b[36msuccess_rate\u001b[0m=\u001b[35m1.0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'chunk_jsonl_parsing', 'duration_ms': 2, 'input_lines': 1, 'output_texts': 1, 'skipped_lines': 0, 'success_rate': 1.0, 'event': 'chunk_jsonl_parsing_completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.331752Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.332505Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component embed       \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35membed\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component embed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.333027Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mtext_embedding_started        \u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mtext_embedding\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'text_embedding', 'input_texts': 1, 'event': 'text_embedding_started', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.333027Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.333560Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mUsing individual embedding processing\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36mtext_count\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text_count': 1, 'component': 'embedder', 'event': 'Using individual embedding processing', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.333560Z'}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48c7e6262b2a4e87841e6afed45a723a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.515186Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35membeddings_generated_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mmode\u001b[0m=\u001b[35mindividual\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'embeddings_generated_total', 'metric_type': 'counter', 'value': 1, 'component': 'embedder', 'mode': 'individual', 'status': 'success', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.515186Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.516013Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mtext_embedding_completed      \u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m182\u001b[0m \u001b[36mfailed_embeddings\u001b[0m=\u001b[35m0\u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mtext_embedding\u001b[0m \u001b[36mprocessing_mode\u001b[0m=\u001b[35mindividual\u001b[0m \u001b[36msuccessful_embeddings\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'text_embedding', 'duration_ms': 182, 'input_texts': 1, 'successful_embeddings': 1, 'failed_embeddings': 0, 'processing_mode': 'individual', 'event': 'text_embedding_completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.516013Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.523536Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component docs        \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mdocs\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component docs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.524361Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdocument_building_started     \u001b[0m \u001b[36minput_embeddings\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_metas\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mdocument_building\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'document_building', 'input_texts': 1, 'input_metas': 1, 'input_embeddings': 1, 'event': 'document_building_started', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.524361Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.524963Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mdocuments_built_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'documents_built_total', 'metric_type': 'counter', 'value': 1, 'component': 'pipeline_glue', 'status': 'success', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.524963Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.525483Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_histogram              \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mdocument_build_batch_size\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mhistogram\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'document_build_batch_size', 'metric_type': 'histogram', 'value': 1, 'component': 'pipeline_glue', 'event': 'metric_histogram', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.525483Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.526006Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDocument building completed   \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36minput_embeddings\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_metas\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moutput_documents\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_texts': 1, 'input_metas': 1, 'input_embeddings': 1, 'output_documents': 1, 'component': 'pipeline_glue', 'event': 'Document building completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.526006Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.526532Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdocument_building_completed   \u001b[0m \u001b[36mdocuments_built\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m2\u001b[0m \u001b[36minput_alignment_ratio\u001b[0m=\u001b[35m1.0\u001b[0m \u001b[36minput_embeddings\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_metas\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mdocument_building\u001b[0m \u001b[36moutput_documents\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'document_building', 'duration_ms': 2, 'input_texts': 1, 'input_metas': 1, 'input_embeddings': 1, 'output_documents': 1, 'input_alignment_ratio': 1.0, 'documents_built': 1, 'event': 'document_building_completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.526532Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.533725Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component write       \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mwrite\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component write\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.534591Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdocument_writing_started      \u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mdocument_writing\u001b[0m \u001b[36mtotal_documents\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'document_writing', 'total_documents': 1, 'event': 'document_writing_started', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.534591Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.535580Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mWriting documents to Qdrant   \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_writer\u001b[0m \u001b[36mdocument_count\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'document_count': 1, 'component': 'qdrant_writer', 'event': 'Writing documents to Qdrant', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.535580Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.617131Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: GET http://localhost:6300 \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: GET http://localhost:6300 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.620504Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: GET http://localhost:6300/collections/memoirr/exists \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: GET http://localhost:6300/collections/memoirr/exists \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.628427Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: DELETE http://localhost:6300/collections/memoirr \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: DELETE http://localhost:6300/collections/memoirr \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.669765Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: PUT http://localhost:6300/collections/memoirr \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: PUT http://localhost:6300/collections/memoirr \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.674836Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: POST http://localhost:6300/collections/memoirr/points \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: POST http://localhost:6300/collections/memoirr/points \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[2m2025-09-20T18:59:17.684818Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: PUT http://localhost:6300/collections/memoirr/points?wait=true \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: PUT http://localhost:6300/collections/memoirr/points?wait=true \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [00:00, 11441.40it/s]          \n",
            "\u001b[2m2025-09-20T18:59:17.688174Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDocuments written successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_writer\u001b[0m \u001b[36mwritten_count\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'written_count': 1, 'component': 'qdrant_writer', 'event': 'Documents written successfully', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.688174Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.689410Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_writer\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mdocuments_written_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'documents_written_total', 'metric_type': 'counter', 'value': 1, 'component': 'qdrant_writer', 'status': 'success', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.689410Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T18:59:17.689988Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdocument_writing_completed    \u001b[0m \u001b[36mdocuments_skipped\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mdocuments_written\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m155\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mdocument_writing\u001b[0m \u001b[36msuccess_rate\u001b[0m=\u001b[35m1.0\u001b[0m \u001b[36mtotal_documents\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'document_writing', 'duration_ms': 155, 'total_documents': 1, 'documents_written': 1, 'documents_skipped': 0, 'success_rate': 1.0, 'event': 'document_writing_completed', 'level': 'info', 'timestamp': '2025-09-20T18:59:17.689988Z'}\n",
            "Pipeline Results:\n",
            "=================\n",
            "Preprocessor: {'total_captions': 3, 'kept': 3, 'dropped_empty': 0, 'dropped_non_english': 0, 'deduped': 0}\n",
            "Chunker: {'input_captions': 3, 'output_chunks': 1, 'avg_tokens_per_chunk': 15.0}\n",
            "Writer: {'written': 1, 'skipped': 0, 'total': 1}\n",
            "✅ SUCCESS! Check Qdrant UI at http://localhost:6300/dashboard to see the embedded chunks!\n",
            "Collection name: memoirr\n"
          ]
        }
      ],
      "source": [
        "# Run the complete end-to-end pipeline: SRT → Preprocess → Chunk → Embed → Qdrant\n",
        "from src.pipelines.srt_to_qdrant import build_srt_to_qdrant_pipeline\n",
        "\n",
        "print('Building the complete SRT-to-Qdrant pipeline...')\n",
        "pipe = build_srt_to_qdrant_pipeline()\n",
        "\n",
        "print('Pipeline components:')\n",
        "for component_name in pipe.graph.nodes:\n",
        "    print(f'  - {component_name}')\n",
        "\n",
        "print('Pipeline connections:')\n",
        "for edge in pipe.graph.edges:\n",
        "    print(f'  - {edge[0]} → {edge[1]}')\n",
        "\n",
        "print('Running pipeline on sample SRT...')\n",
        "result = pipe.run({'pre': {'srt_text': sample_srt}})\n",
        "\n",
        "print('Pipeline Results:')\n",
        "print('=================')\n",
        "\n",
        "# Show preprocessing stats\n",
        "pre_stats = result['pre']['stats']\n",
        "print(f'Preprocessor: {pre_stats}')\n",
        "\n",
        "# Show chunking stats\n",
        "chunk_stats = result['chunk']['stats']\n",
        "print(f'Chunker: {chunk_stats}')\n",
        "\n",
        "# Show write stats\n",
        "write_stats = result['write']['stats']\n",
        "print(f'Writer: {write_stats}')\n",
        "\n",
        "print('✅ SUCCESS! Check Qdrant UI at http://localhost:6300/dashboard to see the embedded chunks!')\n",
        "print('Collection name: memoirr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "969b375d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.959963Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mBuilding RAG pipeline         \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mrag_pipeline_builder\u001b[0m \u001b[36mhas_generator_config\u001b[0m=\u001b[35mFalse\u001b[0m \u001b[36mhas_retriever_config\u001b[0m=\u001b[35mFalse\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing RAG pipeline...\n",
            "{'has_retriever_config': False, 'has_generator_config': False, 'component': 'rag_pipeline_builder', 'event': 'Building RAG pipeline', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.959963Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.962737Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mQdrantRetriever initialized successfully\u001b[0m \u001b[36mcollection_name\u001b[0m=\u001b[35mmemoirr\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_retriever\u001b[0m \u001b[36mqdrant_url\u001b[0m=\u001b[35mhttp://localhost:6300\u001b[0m \u001b[36mreturn_embedding\u001b[0m=\u001b[35mFalse\u001b[0m \u001b[36mscore_threshold\u001b[0m=\u001b[35m0.0\u001b[0m \u001b[36mtop_k\u001b[0m=\u001b[35m10\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'qdrant_url': 'http://localhost:6300', 'collection_name': 'memoirr', 'top_k': 10, 'score_threshold': 0.0, 'return_embedding': False, 'component': 'qdrant_retriever', 'event': 'QdrantRetriever initialized successfully', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.962737Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.965162Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGroqGenerator initialized successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mgroq_generator\u001b[0m \u001b[36mmax_tokens\u001b[0m=\u001b[35m1024\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mllama3-8b-8192\u001b[0m \u001b[36mstream\u001b[0m=\u001b[35mFalse\u001b[0m \u001b[36msystem_prompt_template\u001b[0m=\u001b[35mdefault_system.j2\u001b[0m \u001b[36mtemperature\u001b[0m=\u001b[35m0.7\u001b[0m \u001b[36mtop_p\u001b[0m=\u001b[35m1.0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model': 'llama3-8b-8192', 'max_tokens': 1024, 'temperature': 0.7, 'top_p': 1.0, 'stream': False, 'system_prompt_template': 'default_system.j2', 'component': 'groq_generator', 'event': 'GroqGenerator initialized successfully', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.965162Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.967800Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRAG pipeline built successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mrag_pipeline_builder\u001b[0m \u001b[36mcomponents\u001b[0m=\u001b[35m['retriever', 'generator']\u001b[0m \u001b[36mconnections\u001b[0m=\u001b[35m[('retriever.documents', 'generator.documents')]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'components': ['retriever', 'generator'], 'connections': [('retriever.documents', 'generator.documents')], 'component': 'rag_pipeline_builder', 'event': 'RAG pipeline built successfully', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.967800Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.969491Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRAGPipeline initialized       \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mrag_pipeline_wrapper\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'component': 'rag_pipeline_wrapper', 'event': 'RAGPipeline initialized', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.969491Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.971182Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrag_query_started             \u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mrag_query\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing basic retrieval...\n",
            "{'operation': 'rag_query', 'query_length': 34, 'event': 'rag_query_started', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.971182Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.972630Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting RAG query            \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mrag_pipeline\u001b[0m \u001b[36mhas_filters\u001b[0m=\u001b[35mFalse\u001b[0m \u001b[36mquery_preview\u001b[0m=\u001b[35m\"What is the main character's name?\"\u001b[0m \u001b[36mscore_threshold\u001b[0m=\u001b[35mNone\u001b[0m \u001b[36mtask_type\u001b[0m=\u001b[35mNone\u001b[0m \u001b[36mtop_k\u001b[0m=\u001b[35mNone\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query_preview': \"What is the main character's name?\", 'top_k': None, 'score_threshold': None, 'has_filters': False, 'task_type': None, 'component': 'rag_pipeline', 'event': 'Starting RAG query', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.972630Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.974192Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mrag_orchestration_started     \u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mrag_orchestration\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'rag_orchestration', 'query_length': 34, 'event': 'rag_orchestration_started', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.974192Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.976419Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component retriever   \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mretriever\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component retriever\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.978836Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mqdrant_retrieval_started      \u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mqdrant_retrieval\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'qdrant_retrieval', 'query_length': 34, 'event': 'qdrant_retrieval_started', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.978836Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.979734Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting document retrieval   \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_retriever\u001b[0m \u001b[36mhas_filters\u001b[0m=\u001b[35mFalse\u001b[0m \u001b[36mquery_preview\u001b[0m=\u001b[35m\"What is the main character's name?\"\u001b[0m \u001b[36mscore_threshold\u001b[0m=\u001b[35m0.0\u001b[0m \u001b[36mtop_k\u001b[0m=\u001b[35m10\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query_preview': \"What is the main character's name?\", 'top_k': 10, 'score_threshold': 0.0, 'has_filters': False, 'component': 'qdrant_retriever', 'event': 'Starting document retrieval', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.979734Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.980397Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mretrieval_orchestration_started\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mretrieval_orchestration\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'retrieval_orchestration', 'query_length': 34, 'event': 'retrieval_orchestration_started', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.980397Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.982072Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel resolved via recursive search\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mmodel_utils\u001b[0m \u001b[36mmethod\u001b[0m=\u001b[35mrecursive\u001b[0m \u001b[36mmodel_name\u001b[0m=\u001b[35mqwen3-embedding-0.6B\u001b[0m \u001b[36mresolved_path\u001b[0m=\u001b[35mmodels/chunker/qwen3-embedding-0.6B\u001b[0m \u001b[36mtotal_candidates\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'qwen3-embedding-0.6B', 'resolved_path': 'models/chunker/qwen3-embedding-0.6B', 'method': 'recursive', 'total_candidates': 1, 'component': 'model_utils', 'event': 'Model resolved via recursive search', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.982072Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.983201Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEmbedding model resolved successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36mmodel_name\u001b[0m=\u001b[35mqwen3-embedding-0.6B\u001b[0m \u001b[36mmodel_path\u001b[0m=\u001b[35mmodels/chunker/qwen3-embedding-0.6B\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'qwen3-embedding-0.6B', 'model_path': 'models/chunker/qwen3-embedding-0.6B', 'component': 'embedder', 'event': 'Embedding model resolved successfully', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.983201Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.984227Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTextEmbedder initialized successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36membedding_dimension\u001b[0m=\u001b[35m1024\u001b[0m \u001b[36mmodel_name\u001b[0m=\u001b[35mqwen3-embedding-0.6B\u001b[0m \u001b[36mmodel_path\u001b[0m=\u001b[35mmodels/chunker/qwen3-embedding-0.6B\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'qwen3-embedding-0.6B', 'embedding_dimension': 1024, 'model_path': 'models/chunker/qwen3-embedding-0.6B', 'component': 'embedder', 'event': 'TextEmbedder initialized successfully', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.984227Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.985010Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mtext_embedding_started        \u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mtext_embedding\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'text_embedding', 'input_texts': 1, 'event': 'text_embedding_started', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.985010Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:34.985514Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mUsing individual embedding processing\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36mtext_count\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text_count': 1, 'component': 'embedder', 'event': 'Using individual embedding processing', 'level': 'info', 'timestamp': '2025-09-20T19:06:34.985514Z'}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10bd6f8a6f88418b9b303e1414ebd545",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.042073Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35membeddings_generated_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mmode\u001b[0m=\u001b[35mindividual\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'embeddings_generated_total', 'metric_type': 'counter', 'value': 1, 'component': 'embedder', 'mode': 'individual', 'status': 'success', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T19:06:35.042073Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.043235Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mtext_embedding_completed      \u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m58\u001b[0m \u001b[36mfailed_embeddings\u001b[0m=\u001b[35m0\u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mtext_embedding\u001b[0m \u001b[36mprocessing_mode\u001b[0m=\u001b[35mindividual\u001b[0m \u001b[36msuccessful_embeddings\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'text_embedding', 'duration_ms': 58, 'input_texts': 1, 'successful_embeddings': 1, 'failed_embeddings': 0, 'processing_mode': 'individual', 'event': 'text_embedding_completed', 'level': 'info', 'timestamp': '2025-09-20T19:06:35.043235Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.043871Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mRetrieval orchestration failed\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mretrieval_orchestrator\u001b[0m \u001b[36merror\u001b[0m=\u001b[35m\"'QdrantDocumentStore' object has no attribute 'query_by_embedding'\"\u001b[0m \u001b[36merror_type\u001b[0m=\u001b[35mAttributeError\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m \u001b[36mscore_threshold\u001b[0m=\u001b[35m0.0\u001b[0m \u001b[36mtop_k\u001b[0m=\u001b[35m10\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'error': \"'QdrantDocumentStore' object has no attribute 'query_by_embedding'\", 'error_type': 'AttributeError', 'query_length': 34, 'top_k': 10, 'score_threshold': 0.0, 'component': 'retrieval_orchestrator', 'event': 'Retrieval orchestration failed', 'level': 'error', 'timestamp': '2025-09-20T19:06:35.043871Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.044424Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mretrieval_orchestrator\u001b[0m \u001b[36merror_type\u001b[0m=\u001b[35mAttributeError\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mretrieval_errors_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'retrieval_errors_total', 'metric_type': 'counter', 'value': 1, 'component': 'retrieval_orchestrator', 'error_type': 'AttributeError', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T19:06:35.044424Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.045501Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mretrieval_orchestration_failed\u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m65\u001b[0m \u001b[36merror_message\u001b[0m=\u001b[35m\"Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\"\u001b[0m \u001b[36merror_type\u001b[0m=\u001b[35mRuntimeError\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mretrieval_orchestration\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'retrieval_orchestration', 'duration_ms': 65, 'error_type': 'RuntimeError', 'error_message': \"Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\", 'query_length': 34, 'event': 'retrieval_orchestration_failed', 'level': 'error', 'timestamp': '2025-09-20T19:06:35.045501Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.046315Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mqdrant_retrieval_failed       \u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m67\u001b[0m \u001b[36merror_message\u001b[0m=\u001b[35m\"Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\"\u001b[0m \u001b[36merror_type\u001b[0m=\u001b[35mRuntimeError\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mqdrant_retrieval\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'qdrant_retrieval', 'duration_ms': 67, 'error_type': 'RuntimeError', 'error_message': \"Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\", 'query_length': 34, 'event': 'qdrant_retrieval_failed', 'level': 'error', 'timestamp': '2025-09-20T19:06:35.046315Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.046821Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mRAG orchestration failed      \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mrag_orchestrator\u001b[0m \u001b[36merror\u001b[0m=\u001b[35m\"The following component failed to run:\\nComponent name: 'retriever'\\nComponent type: 'QdrantRetriever'\\nError: Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\"\u001b[0m \u001b[36merror_type\u001b[0m=\u001b[35mPipelineRuntimeError\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m \u001b[36mtask_type\u001b[0m=\u001b[35mNone\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'error': \"The following component failed to run:\\nComponent name: 'retriever'\\nComponent type: 'QdrantRetriever'\\nError: Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\", 'error_type': 'PipelineRuntimeError', 'query_length': 34, 'task_type': None, 'component': 'rag_orchestrator', 'event': 'RAG orchestration failed', 'level': 'error', 'timestamp': '2025-09-20T19:06:35.046821Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.047280Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mrag_orchestrator\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mpipeline_executions_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35merror\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'pipeline_executions_total', 'metric_type': 'counter', 'value': 1, 'component': 'rag_orchestrator', 'status': 'error', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T19:06:35.047280Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.047696Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mrag_orchestrator\u001b[0m \u001b[36merror_type\u001b[0m=\u001b[35mPipelineRuntimeError\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mpipeline_errors_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'pipeline_errors_total', 'metric_type': 'counter', 'value': 1, 'component': 'rag_orchestrator', 'error_type': 'PipelineRuntimeError', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T19:06:35.047696Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.048110Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mrag_orchestration_failed      \u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m73\u001b[0m \u001b[36merror_message\u001b[0m=\u001b[35m\"RAG query failed: The following component failed to run:\\nComponent name: 'retriever'\\nComponent type: 'QdrantRetriever'\\nError: Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\"\u001b[0m \u001b[36merror_type\u001b[0m=\u001b[35mRuntimeError\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mrag_orchestration\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'rag_orchestration', 'duration_ms': 73, 'error_type': 'RuntimeError', 'error_message': \"RAG query failed: The following component failed to run:\\nComponent name: 'retriever'\\nComponent type: 'QdrantRetriever'\\nError: Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\", 'query_length': 34, 'event': 'rag_orchestration_failed', 'level': 'error', 'timestamp': '2025-09-20T19:06:35.048110Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T19:06:35.048601Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mrag_query_failed              \u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m77\u001b[0m \u001b[36merror_message\u001b[0m=\u001b[35m\"RAG query failed: The following component failed to run:\\nComponent name: 'retriever'\\nComponent type: 'QdrantRetriever'\\nError: Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\"\u001b[0m \u001b[36merror_type\u001b[0m=\u001b[35mRuntimeError\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mrag_query\u001b[0m \u001b[36mquery_length\u001b[0m=\u001b[35m34\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'rag_query', 'duration_ms': 77, 'error_type': 'RuntimeError', 'error_message': \"RAG query failed: The following component failed to run:\\nComponent name: 'retriever'\\nComponent type: 'QdrantRetriever'\\nError: Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\", 'query_length': 34, 'event': 'rag_query_failed', 'level': 'error', 'timestamp': '2025-09-20T19:06:35.048601Z'}\n",
            "Error during retrieval: RAG query failed: The following component failed to run:\n",
            "Component name: 'retriever'\n",
            "Component type: 'QdrantRetriever'\n",
            "Error: Retrieval failed: 'QdrantDocumentStore' object has no attribute 'query_by_embedding'\n",
            "\n",
            "✅ Retrieval pipeline tests completed!\n"
          ]
        }
      ],
      "source": [
        "# Retrieval Pipeline Test\n",
        "# This script demonstrates how to use the RAG pipeline to retrieve and generate answers from\n",
        "# indexed content\n",
        "\n",
        "from src.pipelines.rag_pipeline import RAGPipeline\n",
        "\n",
        "# Initialize the RAG pipeline\n",
        "print(\"Initializing RAG pipeline...\")\n",
        "rag = RAGPipeline()\n",
        "\n",
        "# Test basic retrieval with a sample query\n",
        "print(\"\\nTesting basic retrieval...\")\n",
        "query = \"What is the main character's name?\"\n",
        "\n",
        "try:\n",
        "    result = rag.query(query)\n",
        "\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"Retrieved documents: {result['summary']['documents_retrieved']}\")\n",
        "    print(f\"Generated replies: {result['summary']['replies_generated']}\")\n",
        "\n",
        "    if result.get('answer'):\n",
        "        print(f\"Answer: {result['answer']}\")\n",
        "\n",
        "    # Show source documents\n",
        "    if result.get('sources'):\n",
        "        print(\"\\nTop source documents:\")\n",
        "        for i, source in enumerate(result['sources'][:3]):  # Show top 3 sources\n",
        "            print(f\"  {i+1}. {source['content'][:100]}... (score: {source['score']:.3f})\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during retrieval: {e}\")\n",
        "\n",
        "print(\"\\n✅ Retrieval pipeline tests completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "memoirr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

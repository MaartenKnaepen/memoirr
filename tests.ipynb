{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Memoirr: Preprocessor + Chunker Pipeline Smoke Test\n",
        "\n",
        "This notebook runs a minimal Haystack pipeline using the SRT preprocessor and the semantic chunker.\n",
        "\n",
        "Requirements:\n",
        "- Ensure a local sentence-transformers model is available under `models/<EMBEDDING_MODEL_NAME>/` (with `model.safetensors` and tokenizer/config files).\n",
        "- `.env` should set `EMBEDDING_MODEL_NAME` (default included in repo). Optionally set `EMBEDDING_DEVICE` (e.g., `cuda:0`).\n",
        "\n",
        "Notes:\n",
        "- The preprocessor emits cleaned JSONL lines, one per caption.\n",
        "- The chunker uses Chonkie SemanticChunker with the self-hosted embeddings to create time-aware chunks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e9fbc022",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EMBEDDING_MODEL_NAME = qwen3-embedding-0.6B\n",
            "EMBEDDING_DEVICE     = \n",
            "Found candidate model dir at: models/chunker/qwen3-embedding-0.6B\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pathlib\n",
        "import textwrap\n",
        "from src.core.config import get_settings\n",
        "\n",
        "settings = get_settings()\n",
        "print('EMBEDDING_MODEL_NAME =', settings.embedding_model_name)\n",
        "print('EMBEDDING_DEVICE     =', settings.device)\n",
        "\n",
        "# Quick existence check to help the user\n",
        "model_path = pathlib.Path('models') / settings.embedding_model_name\n",
        "if not model_path.exists():\n",
        "    # Fallback: search by terminal folder name (case-insensitive), similar to runtime resolver\n",
        "    target = settings.embedding_model_name.split('/')[-1].lower()\n",
        "    candidates = [p for p in pathlib.Path('models').rglob('*') if p.is_dir() and p.name.lower() == target]\n",
        "    if candidates:\n",
        "        print('Found candidate model dir at:', candidates[0])\n",
        "    else:\n",
        "        print('WARNING: Expected model folder not found under models/. The chunker cell may fail.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1295a593",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1\n",
            "00:00:01,000 --> 00:00:02,000\n",
            "- Hello there!\n",
            "\n",
            "2\n",
            "00:00:02,100 --> 00:00:03,000\n",
            "How are you doing?\n",
            "\n",
            "3\n",
            "00:00:03,100 --> 00:00:04,000\n",
            "I'm fine. Thanks!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sample SRT content (very small)\n",
        "sample_srt = textwrap.dedent('''\n",
        "1\n",
        "00:00:01,000 --> 00:00:02,000\n",
        "- Hello there!\n",
        "\n",
        "2\n",
        "00:00:02,100 --> 00:00:03,000\n",
        "How are you doing?\n",
        "\n",
        "3\n",
        "00:00:03,100 --> 00:00:04,000\n",
        "I'm fine. Thanks!\n",
        "''')\n",
        "print(sample_srt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "end_to_end_pipeline",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:10.723540Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPipelines module initialized  \u001b[0m \u001b[36mavailable_pipelines\u001b[0m=\u001b[35m['srt_to_qdrant']\u001b[0m \u001b[36menvironment\u001b[0m=\u001b[35mdevelopment\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mpipelines\u001b[0m \u001b[36mservice\u001b[0m=\u001b[35mmemoirr\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:10.943916Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mBuilding SRT-to-Qdrant pipeline\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_builder\u001b[0m \u001b[36mpipeline_type\u001b[0m=\u001b[35msrt_to_qdrant\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building the complete SRT-to-Qdrant pipeline...\n",
            "{'pipeline_type': 'srt_to_qdrant', 'component': 'pipeline_builder', 'event': 'Building SRT-to-Qdrant pipeline', 'level': 'info', 'timestamp': '2025-09-20T14:53:10.943916Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:14.258216Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSRTPreprocessor initialized   \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mdedupe_window_ms\u001b[0m=\u001b[35m1000\u001b[0m \u001b[36mmin_len\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'min_len': 1, 'dedupe_window_ms': 1000, 'component': 'preprocessor', 'event': 'SRTPreprocessor initialized', 'level': 'info', 'timestamp': '2025-09-20T14:53:14.258216Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:14.259538Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSemanticChunker initialized   \u001b[0m \u001b[36mchunk_size\u001b[0m=\u001b[35m512\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36mmin_sentences\u001b[0m=\u001b[35m2\u001b[0m \u001b[36msimilarity_window\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mthreshold\u001b[0m=\u001b[35m0.75\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'threshold': '0.75', 'chunk_size': 512, 'similarity_window': 3, 'min_sentences': 2, 'component': 'chunker', 'event': 'SemanticChunker initialized', 'level': 'info', 'timestamp': '2025-09-20T14:53:14.259538Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:14.260471Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mChunkJsonlToTexts initialized \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'component': 'pipeline_glue', 'event': 'ChunkJsonlToTexts initialized', 'level': 'info', 'timestamp': '2025-09-20T14:53:14.260471Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:14.261846Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel resolved via recursive search\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mmodel_utils\u001b[0m \u001b[36mmethod\u001b[0m=\u001b[35mrecursive\u001b[0m \u001b[36mmodel_name\u001b[0m=\u001b[35mqwen3-embedding-0.6B\u001b[0m \u001b[36mresolved_path\u001b[0m=\u001b[35mmodels/chunker/qwen3-embedding-0.6B\u001b[0m \u001b[36mtotal_candidates\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'qwen3-embedding-0.6B', 'resolved_path': 'models/chunker/qwen3-embedding-0.6B', 'method': 'recursive', 'total_candidates': 1, 'component': 'model_utils', 'event': 'Model resolved via recursive search', 'level': 'info', 'timestamp': '2025-09-20T14:53:14.261846Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:14.262464Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEmbedding model resolved successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36mmodel_name\u001b[0m=\u001b[35mqwen3-embedding-0.6B\u001b[0m \u001b[36mmodel_path\u001b[0m=\u001b[35mmodels/chunker/qwen3-embedding-0.6B\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'qwen3-embedding-0.6B', 'model_path': 'models/chunker/qwen3-embedding-0.6B', 'component': 'embedder', 'event': 'Embedding model resolved successfully', 'level': 'info', 'timestamp': '2025-09-20T14:53:14.262464Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:14.367553Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLoad pretrained SentenceTransformer: models/chunker/qwen3-embedding-0.6B\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m227\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load pretrained SentenceTransformer: models/chunker/qwen3-embedding-0.6B\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.763432Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m1 prompt is loaded, with the key: query\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m378\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 prompt is loaded, with the key: query\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.764785Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTextEmbedder initialized successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36membedding_dimension\u001b[0m=\u001b[35m1024\u001b[0m \u001b[36mmodel_name\u001b[0m=\u001b[35mqwen3-embedding-0.6B\u001b[0m \u001b[36mmodel_path\u001b[0m=\u001b[35mmodels/chunker/qwen3-embedding-0.6B\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'qwen3-embedding-0.6B', 'embedding_dimension': 1024, 'model_path': 'models/chunker/qwen3-embedding-0.6B', 'component': 'embedder', 'event': 'TextEmbedder initialized successfully', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.764785Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.765700Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mBuildDocuments initialized    \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'component': 'pipeline_glue', 'event': 'BuildDocuments initialized', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.765700Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.767632Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mQdrantWriter initialized successfully\u001b[0m \u001b[36mcollection_name\u001b[0m=\u001b[35mmemoirr\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_writer\u001b[0m \u001b[36membedding_dimension\u001b[0m=\u001b[35m1024\u001b[0m \u001b[36mqdrant_url\u001b[0m=\u001b[35mhttp://localhost:6300\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'qdrant_url': 'http://localhost:6300', 'collection_name': 'memoirr', 'embedding_dimension': 1024, 'component': 'qdrant_writer', 'event': 'QdrantWriter initialized successfully', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.767632Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.768619Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSRT-to-Qdrant pipeline built successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_builder\u001b[0m \u001b[36mcomponent_names\u001b[0m=\u001b[35m['pre', 'chunk', 'explode', 'embed', 'docs', 'write']\u001b[0m \u001b[36mpipeline_type\u001b[0m=\u001b[35msrt_to_qdrant\u001b[0m \u001b[36mtotal_components\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mtotal_connections\u001b[0m=\u001b[35m7\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'total_components': 6, 'component_names': ['pre', 'chunk', 'explode', 'embed', 'docs', 'write'], 'total_connections': 7, 'pipeline_type': 'srt_to_qdrant', 'component': 'pipeline_builder', 'event': 'SRT-to-Qdrant pipeline built successfully', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.768619Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.787135Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component pre         \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mpre\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline components:\n",
            "  - pre\n",
            "  - chunk\n",
            "  - explode\n",
            "  - embed\n",
            "  - docs\n",
            "  - write\n",
            "Pipeline connections:\n",
            "  - pre → chunk\n",
            "  - chunk → explode\n",
            "  - explode → embed\n",
            "  - explode → docs\n",
            "  - explode → docs\n",
            "  - embed → docs\n",
            "  - docs → write\n",
            "Running pipeline on sample SRT...\n",
            "Running component pre\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.788504Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1msrt_preprocessing_started     \u001b[0m \u001b[36minput_length\u001b[0m=\u001b[35m151\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35msrt_preprocessing\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'srt_preprocessing', 'input_length': 151, 'event': 'srt_preprocessing_started', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.788504Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.789154Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting SRT preprocessing    \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mdedupe_window_ms\u001b[0m=\u001b[35m1000\u001b[0m \u001b[36minput_size_chars\u001b[0m=\u001b[35m151\u001b[0m \u001b[36mmin_len\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_size_chars': 151, 'min_len': 1, 'dedupe_window_ms': 1000, 'component': 'preprocessor', 'event': 'Starting SRT preprocessing', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.789154Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.974633Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCaption language filtering completed\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mdropped_captions\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mdropped_lines\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mkept_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mkept_lines\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mtotal_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mtotal_lines\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'total_captions': 3, 'kept_captions': 3, 'dropped_captions': 0, 'total_lines': 3, 'kept_lines': 3, 'dropped_lines': 0, 'component': 'language_filter', 'event': 'Caption language filtering completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.974633Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.975661Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_language_filtered_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_language_filtered_total', 'metric_type': 'counter', 'value': 3, 'component': 'language_filter', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.975661Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.976279Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_kept_after_language_filter\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mkept\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_kept_after_language_filter', 'metric_type': 'counter', 'value': 3, 'component': 'language_filter', 'status': 'kept', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.976279Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.976839Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_dropped_after_language_filter\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mdropped\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_dropped_after_language_filter', 'metric_type': 'counter', 'value': 0, 'component': 'language_filter', 'status': 'dropped', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.976839Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.977330Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mlines_language_filtered_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'lines_language_filtered_total', 'metric_type': 'counter', 'value': 3, 'component': 'language_filter', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.977330Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.977809Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mlines_kept_after_language_filter\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mkept\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'lines_kept_after_language_filter', 'metric_type': 'counter', 'value': 3, 'component': 'language_filter', 'status': 'kept', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.977809Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.978314Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mlanguage_filter\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mlines_dropped_after_language_filter\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mdropped\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'lines_dropped_after_language_filter', 'metric_type': 'counter', 'value': 0, 'component': 'language_filter', 'status': 'dropped', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.978314Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.978897Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_processed_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_processed_total', 'metric_type': 'counter', 'value': 0, 'component': 'preprocessor', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.978897Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.979398Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_kept_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mkept\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_kept_total', 'metric_type': 'counter', 'value': 3, 'component': 'preprocessor', 'status': 'kept', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.979398Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.979886Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_dropped_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mreason\u001b[0m=\u001b[35mempty\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_dropped_total', 'metric_type': 'counter', 'value': 0, 'component': 'preprocessor', 'reason': 'empty', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.979886Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.981320Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_dropped_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mreason\u001b[0m=\u001b[35mnon_english\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_dropped_total', 'metric_type': 'counter', 'value': 0, 'component': 'preprocessor', 'reason': 'non_english', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.981320Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.981807Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_deduped_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mreason\u001b[0m=\u001b[35mduplicate\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_deduped_total', 'metric_type': 'counter', 'value': 0, 'component': 'preprocessor', 'reason': 'duplicate', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.981807Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.982273Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSRT preprocessing completed   \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpreprocessor\u001b[0m \u001b[36moutput_lines\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mprocessing_stats\u001b[0m=\u001b[35m{'total_captions': 3, 'kept': 3, 'dropped_empty': 0, 'dropped_non_english': 0, 'deduped': 0}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'output_lines': 3, 'processing_stats': {'total_captions': 3, 'kept': 3, 'dropped_empty': 0, 'dropped_non_english': 0, 'deduped': 0}, 'component': 'preprocessor', 'event': 'SRT preprocessing completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.982273Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.982738Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1msrt_preprocessing_completed   \u001b[0m \u001b[36mcaptions_dropped\u001b[0m=\u001b[35m-3\u001b[0m \u001b[36mcaptions_kept\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m194\u001b[0m \u001b[36minput_length\u001b[0m=\u001b[35m151\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35msrt_preprocessing\u001b[0m \u001b[36moutput_lines\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'srt_preprocessing', 'duration_ms': 194, 'input_length': 151, 'output_lines': 3, 'captions_kept': 3, 'captions_dropped': -3, 'event': 'srt_preprocessing_completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.982738Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.983433Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component chunk       \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mchunk\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component chunk\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.984152Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1msemantic_chunking_started     \u001b[0m \u001b[36minput_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35msemantic_chunking\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'semantic_chunking', 'input_captions': 3, 'event': 'semantic_chunking_started', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.984152Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.984652Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting semantic chunking    \u001b[0m \u001b[36mchunk_size\u001b[0m=\u001b[35m512\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36minput_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mthreshold\u001b[0m=\u001b[35m0.75\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_captions': 3, 'threshold': '0.75', 'chunk_size': 512, 'component': 'chunker', 'event': 'Starting semantic chunking', 'level': 'info', 'timestamp': '2025-09-20T14:53:15.984652Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.987024Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mUse pytorch device_name: cuda:0\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m219\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use pytorch device_name: cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:15.987683Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLoad pretrained SentenceTransformer: models/chunker/qwen3-embedding-0.6B\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m227\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load pretrained SentenceTransformer: models/chunker/qwen3-embedding-0.6B\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.118402Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1m1 prompt is loaded, with the key: query\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m378\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35msentence_transformers.SentenceTransformer\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 prompt is loaded, with the key: query\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.121007Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mcaptions_chunked_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m3\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'captions_chunked_total', 'metric_type': 'counter', 'value': 3, 'component': 'chunker', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.121007Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.121971Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mchunks_generated_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'chunks_generated_total', 'metric_type': 'counter', 'value': 1, 'component': 'chunker', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.121971Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.122668Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_histogram              \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mavg_tokens_per_chunk\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mhistogram\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m15.0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'avg_tokens_per_chunk', 'metric_type': 'histogram', 'value': 15.0, 'component': 'chunker', 'event': 'metric_histogram', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.122668Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.123345Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSemantic chunking completed   \u001b[0m \u001b[36mavg_tokens_per_chunk\u001b[0m=\u001b[35m15.0\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mchunker\u001b[0m \u001b[36minput_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36moutput_chunks\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_captions': 3, 'output_chunks': 1, 'avg_tokens_per_chunk': 15.0, 'component': 'chunker', 'event': 'Semantic chunking completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.123345Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.123778Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1msemantic_chunking_completed   \u001b[0m \u001b[36mavg_tokens_per_chunk\u001b[0m=\u001b[35m15.0\u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m1139\u001b[0m \u001b[36minput_captions\u001b[0m=\u001b[35m3\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35msemantic_chunking\u001b[0m \u001b[36moutput_chunks\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moutput_chunks_final\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'semantic_chunking', 'duration_ms': 1139, 'input_captions': 3, 'output_chunks': 1, 'avg_tokens_per_chunk': 15.0, 'output_chunks_final': 1, 'event': 'semantic_chunking_completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.123778Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.124445Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component explode     \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mexplode\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component explode\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.126211Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mchunk_jsonl_parsing_started   \u001b[0m \u001b[36minput_lines\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mchunk_jsonl_parsing\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'chunk_jsonl_parsing', 'input_lines': 1, 'event': 'chunk_jsonl_parsing_started', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.126211Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.127412Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mchunk_lines_processed_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'chunk_lines_processed_total', 'metric_type': 'counter', 'value': 1, 'component': 'pipeline_glue', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.127412Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.128447Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mtexts_extracted_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'texts_extracted_total', 'metric_type': 'counter', 'value': 1, 'component': 'pipeline_glue', 'status': 'success', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.128447Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.129591Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mChunk JSONL parsing completed \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36minput_lines\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moutput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mskipped_lines\u001b[0m=\u001b[35m0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_lines': 1, 'output_texts': 1, 'skipped_lines': 0, 'component': 'pipeline_glue', 'event': 'Chunk JSONL parsing completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.129591Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.130734Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mchunk_jsonl_parsing_completed \u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m4\u001b[0m \u001b[36minput_lines\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mchunk_jsonl_parsing\u001b[0m \u001b[36moutput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mskipped_lines\u001b[0m=\u001b[35m0\u001b[0m \u001b[36msuccess_rate\u001b[0m=\u001b[35m1.0\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'chunk_jsonl_parsing', 'duration_ms': 4, 'input_lines': 1, 'output_texts': 1, 'skipped_lines': 0, 'success_rate': 1.0, 'event': 'chunk_jsonl_parsing_completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.130734Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.133282Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component embed       \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35membed\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component embed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.134413Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mtext_embedding_started        \u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mtext_embedding\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'text_embedding', 'input_texts': 1, 'event': 'text_embedding_started', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.134413Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.135551Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mUsing individual embedding processing\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36mtext_count\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text_count': 1, 'component': 'embedder', 'event': 'Using individual embedding processing', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.135551Z'}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ce7538df9d94a2fa242c342ebd8f187",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.350831Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35membedder\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35membeddings_generated_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mmode\u001b[0m=\u001b[35mindividual\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'embeddings_generated_total', 'metric_type': 'counter', 'value': 1, 'component': 'embedder', 'mode': 'individual', 'status': 'success', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.350831Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.352253Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mtext_embedding_completed      \u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m217\u001b[0m \u001b[36mfailed_embeddings\u001b[0m=\u001b[35m0\u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mtext_embedding\u001b[0m \u001b[36mprocessing_mode\u001b[0m=\u001b[35mindividual\u001b[0m \u001b[36msuccessful_embeddings\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'text_embedding', 'duration_ms': 217, 'input_texts': 1, 'successful_embeddings': 1, 'failed_embeddings': 0, 'processing_mode': 'individual', 'event': 'text_embedding_completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.352253Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.367112Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component docs        \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mdocs\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component docs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.368876Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdocument_building_started     \u001b[0m \u001b[36minput_embeddings\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_metas\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mdocument_building\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'document_building', 'input_texts': 1, 'input_metas': 1, 'input_embeddings': 1, 'event': 'document_building_started', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.368876Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.369664Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mdocuments_built_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'documents_built_total', 'metric_type': 'counter', 'value': 1, 'component': 'pipeline_glue', 'status': 'success', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.369664Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.371300Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_histogram              \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mdocument_build_batch_size\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mhistogram\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'document_build_batch_size', 'metric_type': 'histogram', 'value': 1, 'component': 'pipeline_glue', 'event': 'metric_histogram', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.371300Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.372200Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDocument building completed   \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mpipeline_glue\u001b[0m \u001b[36minput_embeddings\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_metas\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moutput_documents\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_texts': 1, 'input_metas': 1, 'input_embeddings': 1, 'output_documents': 1, 'component': 'pipeline_glue', 'event': 'Document building completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.372200Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.373026Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdocument_building_completed   \u001b[0m \u001b[36mdocuments_built\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m4\u001b[0m \u001b[36minput_alignment_ratio\u001b[0m=\u001b[35m1.0\u001b[0m \u001b[36minput_embeddings\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_metas\u001b[0m=\u001b[35m1\u001b[0m \u001b[36minput_texts\u001b[0m=\u001b[35m1\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mdocument_building\u001b[0m \u001b[36moutput_documents\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'document_building', 'duration_ms': 4, 'input_texts': 1, 'input_metas': 1, 'input_embeddings': 1, 'output_documents': 1, 'input_alignment_ratio': 1.0, 'documents_built': 1, 'event': 'document_building_completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.373026Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.381450Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRunning component write       \u001b[0m \u001b[36mcomponent_name\u001b[0m=\u001b[35mwrite\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m67\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhaystack.core.pipeline.pipeline\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running component write\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.382781Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdocument_writing_started      \u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mdocument_writing\u001b[0m \u001b[36mtotal_documents\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'document_writing', 'total_documents': 1, 'event': 'document_writing_started', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.382781Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.385166Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mWriting documents to Qdrant   \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_writer\u001b[0m \u001b[36mdocument_count\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'document_count': 1, 'component': 'qdrant_writer', 'event': 'Writing documents to Qdrant', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.385166Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.526088Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: GET http://localhost:6300 \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: GET http://localhost:6300 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.530454Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: GET http://localhost:6300/collections/memoirr/exists \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: GET http://localhost:6300/collections/memoirr/exists \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.545917Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: DELETE http://localhost:6300/collections/memoirr \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: DELETE http://localhost:6300/collections/memoirr \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.602068Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: PUT http://localhost:6300/collections/memoirr \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: PUT http://localhost:6300/collections/memoirr \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.608438Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: POST http://localhost:6300/collections/memoirr/points \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: POST http://localhost:6300/collections/memoirr/points \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[2m2025-09-20T14:53:17.630377Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTTP Request: PUT http://localhost:6300/collections/memoirr/points?wait=true \"HTTP/1.1 200 OK\"\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m1025\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhttpx\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP Request: PUT http://localhost:6300/collections/memoirr/points?wait=true \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [00:00, 6301.35it/s]           \n",
            "\u001b[2m2025-09-20T14:53:17.633381Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDocuments written successfully\u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_writer\u001b[0m \u001b[36mwritten_count\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'written_count': 1, 'component': 'qdrant_writer', 'event': 'Documents written successfully', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.633381Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.635153Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mmetric_counter                \u001b[0m \u001b[36mcomponent\u001b[0m=\u001b[35mqdrant_writer\u001b[0m \u001b[36mmetric_name\u001b[0m=\u001b[35mdocuments_written_total\u001b[0m \u001b[36mmetric_type\u001b[0m=\u001b[35mcounter\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35msuccess\u001b[0m \u001b[36mvalue\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric_name': 'documents_written_total', 'metric_type': 'counter', 'value': 1, 'component': 'qdrant_writer', 'status': 'success', 'event': 'metric_counter', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.635153Z'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m2025-09-20T14:53:17.638352Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdocument_writing_completed    \u001b[0m \u001b[36mdocuments_skipped\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mdocuments_written\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mduration_ms\u001b[0m=\u001b[35m255\u001b[0m \u001b[36moperation\u001b[0m=\u001b[35mdocument_writing\u001b[0m \u001b[36msuccess_rate\u001b[0m=\u001b[35m1.0\u001b[0m \u001b[36mtotal_documents\u001b[0m=\u001b[35m1\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'operation': 'document_writing', 'duration_ms': 255, 'total_documents': 1, 'documents_written': 1, 'documents_skipped': 0, 'success_rate': 1.0, 'event': 'document_writing_completed', 'level': 'info', 'timestamp': '2025-09-20T14:53:17.638352Z'}\n",
            "Pipeline Results:\n",
            "=================\n",
            "Preprocessor: {'total_captions': 3, 'kept': 3, 'dropped_empty': 0, 'dropped_non_english': 0, 'deduped': 0}\n",
            "Chunker: {'input_captions': 3, 'output_chunks': 1, 'avg_tokens_per_chunk': 15.0}\n",
            "Writer: {'written': 1, 'skipped': 0, 'total': 1}\n",
            "✅ SUCCESS! Check Qdrant UI at http://localhost:6300/dashboard to see the embedded chunks!\n",
            "Collection name: memoirr\n"
          ]
        }
      ],
      "source": [
        "# Run the complete end-to-end pipeline: SRT → Preprocess → Chunk → Embed → Qdrant\n",
        "from src.pipelines.srt_to_qdrant import build_srt_to_qdrant_pipeline\n",
        "\n",
        "print('Building the complete SRT-to-Qdrant pipeline...')\n",
        "pipe = build_srt_to_qdrant_pipeline()\n",
        "\n",
        "print('Pipeline components:')\n",
        "for component_name in pipe.graph.nodes:\n",
        "    print(f'  - {component_name}')\n",
        "\n",
        "print('Pipeline connections:')\n",
        "for edge in pipe.graph.edges:\n",
        "    print(f'  - {edge[0]} → {edge[1]}')\n",
        "\n",
        "print('Running pipeline on sample SRT...')\n",
        "result = pipe.run({'pre': {'srt_text': sample_srt}})\n",
        "\n",
        "print('Pipeline Results:')\n",
        "print('=================')\n",
        "\n",
        "# Show preprocessing stats\n",
        "pre_stats = result['pre']['stats']\n",
        "print(f'Preprocessor: {pre_stats}')\n",
        "\n",
        "# Show chunking stats\n",
        "chunk_stats = result['chunk']['stats']\n",
        "print(f'Chunker: {chunk_stats}')\n",
        "\n",
        "# Show write stats\n",
        "write_stats = result['write']['stats']\n",
        "print(f'Writer: {write_stats}')\n",
        "\n",
        "print('✅ SUCCESS! Check Qdrant UI at http://localhost:6300/dashboard to see the embedded chunks!')\n",
        "print('Collection name: memoirr')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "memoirr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
